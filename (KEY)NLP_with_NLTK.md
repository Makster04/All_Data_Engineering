## **Introduction to NLP with NLTK**

Natural Language Processing (NLP) is a field of Artificial Intelligence (AI) that enables computers to understand, interpret, and generate human language. The **Natural Language Toolkit (NLTK)** is one of the most popular Python libraries for NLP, providing tools for text processing, tokenization, stemming, lemmatization, POS tagging, and more.

---

## **1. Overview of NLP with NLTK**
### **What is NLP?**
Natural Language Processing (NLP) is a subfield of AI that focuses on the interaction between computers and human language. It enables machines to process and analyze large amounts of text.

### **What is NLTK?**
The **Natural Language Toolkit (NLTK)** is an open-source Python library for working with human language data. It includes:
- Tokenization (splitting text into words/sentences)
- Stemming and Lemmatization (reducing words to their root form)
- Part-of-Speech (POS) tagging
- Named Entity Recognition (NER)
- Sentiment Analysis
- Parsing and Syntactic Analysis

---

## **2. Important Definitions**
### **Tokenization**
Breaking text into words or sentences.
- **Word Tokenization**: Splitting text into individual words.
- **Sentence Tokenization**: Splitting text into sentences.

### **Stemming**
Reducing words to their root form (e.g., "running" → "run").

### **Lemmatization**
Similar to stemming, but it converts words to their base form using a dictionary (e.g., "better" → "good").

### **Part-of-Speech (POS) Tagging**
Assigning grammatical labels to words (e.g., noun, verb, adjective).

### **Named Entity Recognition (NER)**
Identifying entities such as names, locations, organizations in text.

### **Stopwords**
Common words that do not add much meaning (e.g., "the", "is", "and", "a").

### **Bag of Words (BoW)**
A text representation method where words are converted into numerical vectors.

### **Sentiment Analysis**  
Determining the emotional tone of text.  
- **Positive Sentiment**: Text expresses favorable emotions.  
- **Negative Sentiment**: Text conveys unfavorable emotions.  
- **Neutral Sentiment**: Text does not express strong emotions.  

### **Parsing and Syntax**  
Analyzing the grammatical structure of a sentence.  
- **Parsing**: Breaking down a sentence into its components based on grammar rules.  
- **Syntax Analysis**: Checking if a sentence follows correct grammatical structure.
---
### Table Summary

| **Concept**                   | **Definition**                                                              | **Example**                                              |
|--------------------------------|----------------------------------------------------------------------------|----------------------------------------------------------|
| **Tokenization**               | Breaking text into words or sentences.                                     | "I love NLP!" → `["I", "love", "NLP!"]` (Word Tokenization) |
| **Word Tokenization**          | Splitting text into individual words.                                      | "ChatGPT is great." → `["ChatGPT", "is", "great", "."]`  |
| **Sentence Tokenization**      | Splitting text into sentences.                                             | "I love NLP. It's fascinating!" → `["I love NLP.", "It's fascinating!"]` |
| **Stemming**                   | Reducing words to their root form.                                         | "Running", "runner" → "run"                             |
| **Lemmatization**              | Converts words to their base form using a dictionary.                      | "Better" → "Good", "Am" → "Be"                          |
| **Part-of-Speech (POS) Tagging** | Assigning grammatical labels to words.                                    | "The dog runs." → `("The", DET), ("dog", NOUN), ("runs", VERB)` |
| **Named Entity Recognition (NER)** | Identifying entities such as names, locations, and organizations.        | "Apple Inc. is based in California." → `("Apple Inc.", ORG), ("California", LOC)` |
| **Stopwords**                  | Common words that do not add much meaning.                                | "The cat is on the mat." (Stopwords: "the", "is", "on") |
| **Bag of Words (BoW)**         | A text representation method where words are converted into numerical vectors. | "I love NLP" → `{I: 1, love: 1, NLP: 1}` |
| **Sentiment Analysis**         | Determining the emotional tone of text.                                   | "I love this product!" → **Positive Sentiment** |
| **Parsing and Syntax**         | Analyzing the grammatical structure of a sentence.                        | "The quick brown fox jumps over the lazy dog." (Parsed tree) |

---

## **3. Coding with NLTK**
### **Installation**
```bash
pip install nltk
```
Import NLTK and download necessary datasets:
```python
import nltk
nltk.download('punkt')  # For tokenization
nltk.download('stopwords')  # Stopwords
nltk.download('averaged_perceptron_tagger')  # POS tagging
nltk.download('wordnet')  # Lemmatization
nltk.download('maxent_ne_chunker')  # Named Entity Recognition
nltk.download('words')  # Named Entity Recognition
```

---

### **Example 1: Tokenization**
```python
from nltk.tokenize import word_tokenize, sent_tokenize

text = "Natural Language Processing (NLP) is an exciting field. It enables computers to understand human language."
word_tokens = word_tokenize(text)
sentence_tokens = sent_tokenize(text)

print("Word Tokenization:", word_tokens)
print("Sentence Tokenization:", sentence_tokens)
```
```
Word Tokenization: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'an', 'exciting', 'field', '.', 'It', 'enables', 'computers', 'to', 'understand', 'human', 'language', '.']
Sentence Tokenization: ['Natural Language Processing (NLP) is an exciting field.', 'It enables computers to understand human language.']
```

---

### **Example 2: Removing Stopwords**
```python
from nltk.corpus import stopwords

stop_words = set(stopwords.words('english'))
filtered_words = [word for word in word_tokens if word.lower() not in stop_words]

print("Filtered Words (Without Stopwords):", filtered_words)
```
```
Filtered Words (Without Stopwords): ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'exciting', 'field', '.', 'enables', 'computers', 'understand', 'human', 'language', '.']
```

---

### **Example 3: Stemming and Lemmatization**
```python
from nltk.stem import PorterStemmer, WordNetLemmatizer

stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()

words = ["running", "flies", "easily", "better"]

print("Stemming Results:")
for word in words:
    print(word, "→", stemmer.stem(word))

print("\nLemmatization Results:")
for word in words:
    print(word, "→", lemmatizer.lemmatize(word))
```
```
# Stemming
Stemming Results:
running → run
flies → fli
easily → easili
better → better

# Lemmatization
Lemmatization Results:
running → running
flies → fly
easily → easily
better → better
```

---

### **Example 4: Part-of-Speech (POS) Tagging**
```python
from nltk import pos_tag

pos_tags = pos_tag(word_tokens)
print("POS Tags:", pos_tags)
```
```
POS Tags: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('an', 'DT'), ('exciting', 'JJ'), ('field', 'NN'), ('.', '.'), ('It', 'PRP'), ('enables', 'VBZ'), ('computers', 'NNS'), ('to', 'TO'), ('understand', 'VB'), ('human', 'JJ'), ('language', 'NN'), ('.', '.')]
```

---

### **Example 5: Named Entity Recognition (NER)**
```python
from nltk import ne_chunk

nltk.download('maxent_ne_chunker')
nltk.download('words')

ner_tree = ne_chunk(pos_tags)
print(ner_tree)
```
```
(S
  (GPE Natural/NNP)
  Language/NNP
  Processing/NNP
  (ORGANIZATION NLP/NNP)
  is/VBZ
  an/DT
  exciting/JJ
  field/NN
  ./.
  It/PRP
  enables/VBZ
  computers/NNS
  to/TO
  understand/VB
  human/JJ
  language/NN
  ./.)

```

---

### **Example 6: Bag of Words Representation**
```python
from sklearn.feature_extraction.text import CountVectorizer

corpus = [
    "NLP is amazing.",
    "I love natural language processing.",
    "Machines can understand human language."
]

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)

print("Bag of Words Representation:")
print(X.toarray())
print("Feature Names:", vectorizer.get_feature_names_out())
```
```
Bag of Words Representation:
[[0 0 1 0 0 1 0 0 1]
 [1 0 0 0 1 1 1 1 0]
 [0 1 0 1 0 0 1 1 1]]
Feature Names: ['amazing', 'can', 'human', 'is', 'language', 'love', 'machines', 'natural', 'processing']
```

### **Example 7: Sentiment Analysis Example (Using `TextBlob`)**
```python
from textblob import TextBlob

# Example text
text = "I love this game! The players are amazing."

# Perform sentiment analysis
blob = TextBlob(text)
sentiment_score = blob.sentiment.polarity  # Ranges from -1 (negative) to 1 (positive)

# Determine sentiment category
if sentiment_score > 0:
    sentiment = "Positive"
elif sentiment_score < 0:
    sentiment = "Negative"
else:
    sentiment = "Neutral"

print(f"Sentiment Score: {sentiment_score}, Sentiment: {sentiment}")
```
```
Sentiment Score: 0.75, Sentiment: Positive
```

### **Example 8: Parsing and Syntax Analysis Example (Using `spacy`)**
```python
import spacy

# Load English model
nlp = spacy.load("en_core_web_sm")

# Example sentence
sentence = "The quick brown fox jumps over the lazy dog."

# Parse the sentence
doc = nlp(sentence)

# Print dependency parsing results
for token in doc:
    print(f"Word: {token.text}, POS: {token.pos_}, Dependency: {token.dep_}")
```
```
"The quick brown fox jumps over the lazy dog."
```
```
Word: The, POS: DET, Dependency: det
Word: quick, POS: ADJ, Dependency: amod
Word: brown, POS: ADJ, Dependency: amod
Word: fox, POS: NOUN, Dependency: nsubj
Word: jumps, POS: VERB, Dependency: ROOT
Word: over, POS: ADP, Dependency: prep
Word: the, POS: DET, Dependency: det
Word: lazy, POS: ADJ, Dependency: amod
Word: dog, POS: NOUN, Dependency: pobj
Word: ., POS: PUNCT, Dependency: punct
```
---

## **4. Applications of NLP with NLTK**
- **Chatbots**
- **Sentiment Analysis**
- **Text Summarization**
- **Machine Translation**
- **Speech Recognition**
- **Spam Detection**

---

## **5. Summary**
- **NLTK** is a powerful library for NLP tasks.
- **Tokenization**, **stemming**, **lemmatization**, **POS tagging**, and **NER** are fundamental NLP tasks.
- **Stopwords** are removed to improve efficiency.
- **Bag of Words (BoW)** is a popular way to represent text numerically.


Here are some of the ways that NLTK can make our lives easier when working with text data:

- **Stop Word Removal:** NLTK contains a full library of stop words, making it easy to remove the words that don't matter from our data.

- **Filtering and Cleaning:** NLTK provides simple, easy ways to create and filter frequency distributions, as well providing multiple ways to clean, stem, lemmatize, or tokenize datasets.

- **Feature Selection and Feature Engineering:** NLTK contains tools to quickly generate features such as bigrams and n-grams. It also contains major libraries such as the Penn Tree Bank to allow quick feature engineering, such as generating part-of-speech tags, or sentence polarity.

    - **Bigrams:** Pairs of two consecutive words in a text, used in language processing to understand word relationships and predict the next word.  
    
    - **N-grams:** Groups of *n* consecutive words in a sentence, helping computers analyze language patterns, predict words, and improve text-based applications.  
    
    - **Penn Treebank:** A collection of sentences with grammar labels, used to train language models and help computers understand sentence structures better.
 
 ![image](https://github.com/user-attachments/assets/d6ca6a1d-eeec-4dcb-ab02-63d3460b897b)



